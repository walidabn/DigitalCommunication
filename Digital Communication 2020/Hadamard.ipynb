{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principles of Digital Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do : \n",
    "- Avec le simple repetition code (pas de parity check), avec un message de 10 charactères, déterminer le nombre de répétitions à partir duquel sur 100 runs, aucune erreur n'est obtenue. Super important : c'est la baseline qu'on va utiliser comme nombre pour parity_incrust sur le second point.\n",
    "- Avec le code hybride : jouer avec les paramètres k, block_length, parity_incrust, batch_size ( avec batch_size == block_length), pour déterminer les paramètres optimaux pour que sur 100 runs, il n'y ait pas d'erreurs. Je doute que ce nombre vaille 0, mais bon, c'est de l'optimisation, c'est vous les data scientists :) . \n",
    "- En réalité, le code \"hybride\" est une variante du LDPC (une méthode d'encodage qui est utilisée dans le standard de la 5G) que j'ai essayé d'implémenter, mais qui n'est pas optimale. Pour faire simple, mon code hybride utilise 1 parity bit par set disjoint de 8 bits d'information, l'optimisation du LDPC consiste à rajouter des bits de protection sur des set non-disjoints. Par exemple : imaginez que vous avez 24 bits d'information à protéger, le code hybride va avoir un bit de parity après le 8ème bit, un bit de parity après le 16ème bit, et un bit de parity après le 24ème bit. Le LDPC va rajouter un bit de parity qui couvre les bits 1 à 8, puis un bit de parity qui couvre les bits 7 à 14, puis un bit de parity qui couvre les bits 12 à 19, puis un bit de parity qui couvre les bits 17 à 24. En gros, les bits de parity couvrent des \"overlapping sets\", mais faut en rajouter. Je soupçonne que si c'est bien implémenté, on peut atteindre un rate beaucoup plus bas, en ayant besoin de moins de répétitions, faut l'implémenter.\n",
    "- Explorer ce qu'il est possible de faire avec d'autres types de codes : si vous pouvez explorer les \"Tornado Codes\" (qui sont , \"Reed-Solomon codes\", \"Turbo Codes\" et \"Reed-Muller Codes\", ce serait top! En fait, il faut savoir que le code sur lequel on a travaillé dans le homework 2 (le Hadamard Code), est en fait un cas particulier d'un Reed-Muller code. Vous pouvez partir de là."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "import numpy as np\n",
    "from scipy.linalg import hadamard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"input.txt\"\n",
    "output = \"output.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of characters from a given textfile\n",
    "text = helpers.read_text_file(input)\n",
    "\n",
    "# Convert text to binary\n",
    "text_binary = helpers.chars_to_bits_partial(text)\n",
    "\n",
    "# Convert binary text to -1 and 1's, useful later for comparison\n",
    "text_for_compare = helpers.from_zero_to_neg(text_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Divide our 640 bits message into 64 chunks of size 10 \n",
    "chunks = []\n",
    "for i in range(0,len(text_binary)-10,10):\n",
    "    chunks.append(text_binary[i:i+10])\n",
    "    \n",
    "last_chunk = []\n",
    "last_chunk.extend(text_binary[-10:-1])\n",
    "\n",
    "last_bit = text_binary[-1]\n",
    "print(len(chunks))\n",
    "print(len(chunks[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Hadamard Matrix\n",
    "hadam = hadamard(512)\n",
    "hadam_2 = hadamard(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# Convert our chunks to a base 10 representation\n",
    "base10_chunks = []\n",
    "for chunk in chunks:\n",
    "    base10_repr = helpers.to_base10(chunk)\n",
    "    base10_chunks.append(base10_repr)\n",
    "\n",
    "base10_lastchunk = helpers.to_base10(last_chunk)\n",
    "print(len(base10_chunks))\n",
    "print(base10_lastchunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create message according to hadamard matrix\n",
    "encoded_message = []\n",
    "for c in base10_chunks:\n",
    "    if c < 512:\n",
    "        encoded_message.append(hadam[c])\n",
    "    else :\n",
    "        encoded_message.append(-hadam[c-512])\n",
    "\n",
    "c = base10_lastchunk\n",
    "if c < 256 : \n",
    "    encoded_message.append(hadam_2[c])\n",
    "else : \n",
    "    encoded_message.append(-hadam_2[c-256])\n",
    "        \n",
    "last_bit_rep = []\n",
    "for i in range(120):\n",
    "    last_bit_rep.append(last_bit)\n",
    "\n",
    "encoded_message.append(last_bit_rep)\n",
    "encoded_message_flat = [item for sublist in encoded_message for item in sublist]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32632"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_message_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file \n",
    "np.savetxt(\"encoded.txt\",encoded_message_flat,fmt='%i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending to server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run client.py --input_file=\"encoded.txt\" --output_file=\"received.txt\" --srv_hostname=iscsrv72.epfl.ch --srv_port=80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read output file\n",
    "output = open('received.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert output from char to float \n",
    "output = [float(i) for i in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.asarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadam = np.asarray(hadam)\n",
    "hadam_2 = np.asarray(hadam_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide our message into 64 chunks of size 512\n",
    "output_chunks = []\n",
    "for i in range(0,len(output)-256-120,512):\n",
    "    output_chunks.append(output[i:i+512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_chunks = np.asarray(output_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create U matrix for decoding\n",
    "U = []\n",
    "for c in output_chunks :\n",
    "    U.append(np.matmul(hadam,c))\n",
    "U = np.asarray(U)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index of max of each line:\n",
    "U_max_indices = []\n",
    "for line in U:\n",
    "    U_max_indices.append(helpers.get_max_index(line))\n",
    "U_max_indices = np.asarray(U_max_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode \n",
    "U_max_indices_binary = []\n",
    "for i in range(len(U_max_indices)):\n",
    "    max_index = U_max_indices[i]\n",
    "    if(U[i,max_index]<0):\n",
    "        for c in \"{0:010b}\".format(max_index+512):\n",
    "            U_max_indices_binary.append(int(c))\n",
    "    else:\n",
    "        for c in \"{0:010b}\".format(max_index):\n",
    "                U_max_indices_binary.append(int(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode_last_bloc_9 (1)\n",
    "\n",
    "last_bloc9 = output[-376:-120]\n",
    "last_bloc9 = np.asarray(last_bloc9)\n",
    "U2 = []\n",
    "U2.append(np.matmul(hadam_2,last_bloc9))\n",
    "U2 = np.asarray(U2)\n",
    "U2_max_index = []\n",
    "for line in U2 : \n",
    "    U2_max_index.append(helpers.get_max_index(line))\n",
    "U2_max_index = np.asarray(U2_max_index)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode last bloc 9 (2)\n",
    "U2_max_index_binary = [] \n",
    "max_index_2 = U2_max_index[0]\n",
    "if U2[0,max_index_2] < 0 : \n",
    "    for c in \"{0:09b}\".format(max_index_2+256):\n",
    "        U2_max_index_binary.append(int(c))\n",
    "else : \n",
    "    for c in \"{0:09b}\".format(max_index_2):\n",
    "        U2_max_index_binary.append(int(c))\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U2_max_index_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode last bit\n",
    "last_bit_rep = output[-120:]\n",
    "acc = 0\n",
    "last_bit = 0\n",
    "for i in range(len(last_bit_rep)):\n",
    "    acc += last_bit_rep[i]\n",
    "\n",
    "if acc > 0 : \n",
    "    last_bit = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all \n",
    "\n",
    "for b in range(len(U2_max_index_binary)):\n",
    "    U_max_indices_binary.append(U2_max_index_binary[b])\n",
    "U_max_indices_binary.append(last_bit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(U_max_indices_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpers.compute_Hamming(U_max_indices_binary,text_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FtIWW9JH2+XjOJfexiSouSOWPLdyVGHDm4ZjnlCgLb6zdRnTXd08tv1F+C+CDFdwlNMFCMx+bYe0gmLI'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpers.from_bits_to_chars(U_max_indices_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
